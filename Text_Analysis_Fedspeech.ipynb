{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install and load library\n",
    "# update.packages(ask = FALSE)\n",
    "# install.packages(\"NLP\", dependencies=TRUE)\n",
    "# install.packages(\"slam\", dependencies=TRUE)\n",
    "# install.packages(\"tm\", dependencies=TRUE) # for text mining\n",
    "# install.package(\"SnowballC\", dependencies=TRUE) # for text stemming\n",
    "# install.packages(\"wordcloud\", dependencies=TRUE)# word-cloud generator\n",
    "# install.packages(\"RColorBrewer\", dependencies=TRUE) # color palettes\n",
    "# install.packages('lda', dependencies=TRUE)\n",
    "# install.packages('modeltools', dependencies=TRUE)\n",
    "# install.packages('stats4', dependencies=TRUE)\n",
    "# # install.packages('methods', dependencies=TRUE)\n",
    "# install.packages('toppicmodels', dependencies=TRUE)\n",
    "# install.packages('ggplot2', dependencies = TRUE)\n",
    "# install.packages(\"NbClust\", dependencies = TRUE)\n",
    "# install.packages(\"factoextra\", dependencies = TRUE)\n",
    "\n",
    "# install.packages(\"lda\", dependencies = TRUE)\n",
    "# install.packages(\"MASS\", dependencies = TRUE)\n",
    "# install.packages(\"topicmodels\", dependencies = TRUE)\n",
    "# install.packages(\"lsa\", dependencies = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"/home/harish/PycharmProjects/Topic-Modeling/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: RColorBrewer\n",
      "\n",
      "Attaching package: ‘ggplot2’\n",
      "\n",
      "The following object is masked from ‘package:NLP’:\n",
      "\n",
      "    annotate\n",
      "\n",
      "Welcome! Related Books: `Practical Guide To Cluster Analysis in R` at https://goo.gl/13EFCZ\n"
     ]
    }
   ],
   "source": [
    "library(NLP)\n",
    "library(tm)\n",
    "library(SnowballC)\n",
    "library(wordcloud)\n",
    "library(RColorBrewer)\n",
    "library(ggplot2)\n",
    "library(factoextra)\n",
    "# library(cluster)\n",
    "library(NbClust)\n",
    "library(lsa)\n",
    "# library(fpc)\n",
    "\n",
    "#LDA\n",
    "\n",
    "library(lda)\n",
    "library(MASS)\n",
    "library(topicmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Length     Class      Mode \n",
       "        1 character character "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## BUILDING CORPUS\n",
    "\n",
    "folder <-\"/home/harish/PycharmProjects/Topic-Modeling/Data Extraction/dataset/manual_93_2005\"\n",
    "summary(folder)\n",
    "corpus_name <- Corpus(DirSource(folder, recursive=TRUE),readerControl = list(reader=readPlain));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<SimpleCorpus>>\n",
       "Metadata:  corpus specific: 1, document level (indexed): 0\n",
       "Content:  documents: 102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"dimension before:\"\n",
      "<<DocumentTermMatrix (documents: 102, terms: 7507)>>\n",
      "Non-/sparse entries: 100833/664881\n",
      "Sparsity           : 87%\n",
      "Maximal term length: 20\n",
      "Weighting          : term frequency (tf)\n",
      "[1] \"dimension after:\"\n",
      "<<DocumentTermMatrix (documents: 102, terms: 10198)>>\n",
      "Non-/sparse entries: 83679/956517\n",
      "Sparsity           : 92%\n",
      "Maximal term length: 142\n",
      "Weighting          : term frequency (tf)\n"
     ]
    }
   ],
   "source": [
    "#---------------Data preprocessing:\n",
    "print(\"dimension before:\");\n",
    "print(DocumentTermMatrix(corpus_name));\n",
    "\n",
    "corpus_name<-tm_map(corpus_name,PlainTextDocument);\n",
    "corpus_name<-tm_map(corpus_name, content_transformer(tolower));\n",
    "corpus_name<-tm_map(corpus_name,removeWords,stopwords(\"english\"));\n",
    "corpus_name<-tm_map(corpus_name,removePunctuation);\n",
    "corpus_name<-tm_map(corpus_name,removeNumbers);\n",
    "corpus_name<-tm_map(corpus_name,stripWhitespace);\n",
    "\n",
    "words_to_remove_in_article<-c(\"system\",\"reserve\",\"tthe\",\"rnthe\", \"continue\", \"open\",\"committee\", \"federal\", \"also\", \"meeting\", \"FOMC\", \"\\r\",\"\\t\",\"Present\", \"\\n\", 'year') #irrevalant words\n",
    "corpus_name<-tm_map(corpus_name, removeWords,words_to_remove_in_article); #removing irrevalant words in the article\n",
    "\n",
    "corpus_name<-tm_map(corpus_name, stemDocument, language=\"english\");\n",
    "\n",
    "print(\"dimension after:\");\n",
    "print(DocumentTermMatrix(corpus_name));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo: change the bounds, weighttfidf, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 4091  102\n",
      "[1]  102 4091\n"
     ]
    }
   ],
   "source": [
    "#----------------------Text Analysis------\n",
    "\n",
    "##build tdm/dtm matrix\n",
    "tdm <- TermDocumentMatrix(corpus_name,control=list(wordLengths=c(4,Inf),bounds = list(global = c(2,Inf))))\n",
    "tdm_matrix <- as.matrix(tdm)\n",
    "print(dim(tdm_matrix))\n",
    "##build a document/term matrix... words must have length 4\n",
    "dtm <- DocumentTermMatrix(corpus_name,control=list(wordLengths=c(4,Inf),bounds = list(global = c(2,Inf))))\n",
    "dtm_matrix <- as.matrix(dtm)\n",
    "print(dim(dtm_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtms <- removeSparseTerms(dtm, 0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word freq\n",
      "growth   growth 2970\n",
      "price     price 2911\n",
      "econom   econom 2238\n",
      "increas increas 2210\n",
      "inflat   inflat 1934\n",
      "polici   polici 1915\n",
      "quarter quarter 1895\n",
      "busi       busi 1494\n",
      "consum   consum 1450\n",
      "period   period 1438\n"
     ]
    }
   ],
   "source": [
    "m <- as.matrix(tdm)\n",
    "v <- sort(rowSums(m), decreasing=TRUE)\n",
    "d <- data.frame(word = names(v),freq=v)\n",
    "print(head(d, 10))\n",
    "# print(findFreqTerms(dtm,lowfreq = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svs = sort.list(abs(svd(dtms)$v[,4]), decreasing = TRUE)\n",
    "# dtms$dimnames$Terms[head(svs, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##return top words by concept\n",
    "\n",
    "##first create function to return top words; require dtms\n",
    "concept<-function(num){ \n",
    "  sv<-sort.list((svd(dtms))$v[,num],decreasing = FALSE)\n",
    "  # print(sv)\n",
    "  # print(dtms$dimnames)\n",
    "  dm<-dtms$dimnames$Terms[head(sv,5)] \n",
    "  return(dm)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##how many words?\n",
    "num <- 102\n",
    "i <- 1:num\n",
    "val <- sapply(i, concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write.table(val,file=paste(\"/home/harish/PycharmProjects/Topic-Modeling/val.csv\"), append = T)\n",
    "# ldaGibbs5@gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##how many words?\n",
    "# num <- 5\n",
    "# i <- 1:num\n",
    "# sapply(i, concept)\n",
    "# # https://stackoverflow.com/questions/14875493/lda-with-topicmodels-how-can-i-see-which-topics-different-documents-belong-to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k=5\n",
    "# ldaGibbs5 <-LDA(dtms, k, method = \"Gibbs\") \n",
    "# #docs to topics \n",
    "# ldaGibbs5.topics <- as.matrix(topics(ldaGibbs5))\n",
    "# #get probability of each topic in each doc\n",
    "# topicProbabilities <- as.data.frame(ldaGibbs5@gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topicProbabilities\n",
    "# nrow(ldaGibbs5@gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector <- NULL\n",
    "# for(i in 1:nrow(ldaGibbs5@gamma)) {\n",
    "#   vector <- c(vector, ldaGibbs5@gamma[i,])\n",
    "# }\n",
    "\n",
    "\n",
    "# Concepts <- rep(c(\"Concept 1\",\"Concept 2\",\"Concept 3\", \"Concept 4\",\"Concept 5\"),times=102)#why 80?\n",
    "# TimeByDocs <- as.numeric(rep(1:102,each=5))\n",
    "# chartdata <- data.frame(Concepts,TimeByDocs,vector)\n",
    "# myplot <- ggplot(chartdata, aes(x=TimeByDocs,y=vector,fill=Concepts)) + geom_area()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggsave(filename=\"myPlot.png\", plot=myplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l<-c()\n",
    "# i <- 0\n",
    "# for (j in 1993:2005){\n",
    "#    l[i] <- j\n",
    "#     i <- i + 1\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in write.table(val, file = paste(\"/home/harish/PycharmProjects/Topic-Modeling/val.csv\"), :\n",
      "“appending column names to file”Saving 6.67 x 6.67 in image\n"
     ]
    }
   ],
   "source": [
    "##how many words?\n",
    "# for (k in 2:5){\n",
    "\n",
    "    num <- 102\n",
    "    i <- 1:num\n",
    "    val <- sapply(i, concept)\n",
    "    # https://stackoverflow.com/questions/14875493/lda-with-topicmodels-how-can-i-see-which-topics-different-documents-belong-to\n",
    "    \n",
    "k = 4\n",
    "\n",
    "    ldaGibbs_k <-LDA(dtms, k, method = \"Gibbs\") \n",
    "    #docs to topics \n",
    "    ldaGibbs_k.topics <- as.matrix(topics(ldaGibbs_k))\n",
    "    #get probability of each topic in each doc\n",
    "    topicProbabilities <- as.data.frame(ldaGibbs_k@gamma)\n",
    "write.table(val,file=paste(\"/home/harish/PycharmProjects/Topic-Modeling/val.csv\"), append = T)\n",
    "\n",
    "    vector <- NULL\n",
    "    for(i in 1:nrow(ldaGibbs_k@gamma)) {\n",
    "      vector <- c(vector, ldaGibbs_k@gamma[i,])\n",
    "    }\n",
    "\n",
    "\n",
    "    Concepts <- rep(c(\"Concept 1\",\"Concept 2\",\"Concept 3\", \"Concept 4\",\"Concept 5\"),times=102)#why 80?\n",
    "    TimeByDocs <- as.numeric(rep(1:102,each=k))\n",
    "    chartdata <- data.frame(Concepts,TimeByDocs,vector)\n",
    "    myplot <- ggplot(chartdata, aes(x=TimeByDocs,y=vector,fill=Concepts)) + geom_area()\n",
    "    plotname <- paste(k,\"png\", sep=\".\");\n",
    "    ggsave(filename=plotname, plot=myplot)\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concepts <- rep(c(\"Concept 1\",\"Concept 2\",\"Concept 3\", \"Concept 4\",\"Concept 5\"),times=102)#why 80?\n",
    "#     TimeByDocs <- as.numeric(rep(c(\"1993\",\"1994\",\"1995\",\"1996\",\"1997\",\"1998\",\"1999\",\n",
    "#                                    \"2000\",\"2001\",\"2002\",\"2003\",\"2004\",\"2005\"),each=k))\n",
    "#     chartdata <- data.frame(Concepts,TimeByDocs,vector)\n",
    "#     myplot <- ggplot(chartdata, aes(x=TimeByDocs,y=vector,fill=Concepts)) + geom_area()\n",
    "# myplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in write.table(topicProbabilities, file = paste(\"/home/harish/PycharmProjects/Topic-Modeling/val.csv\"), :\n",
      "“appending column names to file”"
     ]
    }
   ],
   "source": [
    "\n",
    "write.table(topicProbabilities,file=paste(\"/home/harish/PycharmProjects/Topic-Modeling/val.csv\"), append = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
