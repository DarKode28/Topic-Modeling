{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Text using custom stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/harish/PycharmProjects/Topic-Modeling/Data Extraction/dataset/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading each file names\n",
    "for fn in os.listdir('.'):\n",
    "     if os.path.isfile(fn):\n",
    "            tx = open(fn, 'r+')\n",
    "            print(fn)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_stopwords = ['member','members','manager','january', 'february', 'march', \n",
    "                    'april', 'may', 'june', 'july','august', 'september', 'october', \n",
    "                    'november', 'december',\"system\",\"reserve\",\"rate\", \"continue\", \n",
    "                    \"open\",\"committee\", \"federal\", \"market\", \"member\", \n",
    "                    \"recent\", \"meeting\", \"FOMC\", \"\\r\",\"\\t\",\"Present\", \"\\n\", 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in custom_stopwords:\n",
    "    stopwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-55-6d893459e3ed>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-6d893459e3ed>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    fout = open(directory+ fn, \"w+\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#reading each file names\n",
    "path = '/home/harish/PycharmProjects/Topic-Modeling/Data Extraction/dataset/'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for fn in files:\n",
    "        lst = []\n",
    "        os.chdir(root)\n",
    "        fin = open(fn, \"r\")\n",
    "#         directory = root+\"/out/\"\n",
    "        directory = path + '1993_2007/'\n",
    "        \n",
    "        if not os.path.exists(directory):\n",
    "            print(\"SDF\")\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        fout = open(directory+ fn, \"w+\")\n",
    "        for w in fin.read().lower().split():\n",
    "            each_word = w.lower().strip(string.punctuation)#March, becomes march\n",
    "            if each_word not in stopwords:\n",
    "#                 lst.append(w)\n",
    "#                 if  each_word == 'march':\n",
    "#                     print(w)\n",
    "        \n",
    "        fout = open(directory+ fn, \"w+\")\n",
    "        fout.write(\" \".join(lst))\n",
    "        \n",
    "        fin.close()\n",
    "        fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this if you want remove all the out/ folders automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading each file names\n",
    "path = '/home/harish/PycharmProjects/Topic-Modeling/Data Extraction/dataset/'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for fn in files:\n",
    "        lst = []\n",
    "        os.chdir(root)\n",
    "        fin = open(fn, \"r\")\n",
    "        directory = root+\"/out/\"\n",
    "        \n",
    "        try:\n",
    "            shutil.rmtree(directory)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
